# mini-transformer

**A transformer-based chatbot trained on Persian(Dari) conversation data with reinforcement learning from human feedback (RLHF).

**Features : 
Transformer Architecture: Custom implementation with multi-head attention

Persian(Dari) Language: Trained on Persian conversation corpus

RLHF Training: Reinforcement learning from human feedback

Dynamic Vocabulary: Expands vocabulary with new user inputs

Checkpoint System: Saves and loads training progress

CPU Optimization: Batched data loading with gradual feeding for memory efficiency

**Requirements : 
python
torch
os
math

**Usage : 
The model trains on Persian dialogue data and can generate contextual responses. Includes dynamic learning to handle new vocabulary and conversation patterns. Optimized for CPU with batched processing to handle large datasets efficiently.

note : Trained on emotional expressions, animals, colors, foods, and daily conversations for children

**story behind it: I was enthusiastic to code an Educational AI , particularly made for children. and this project it its first segment
